{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOWVCa4GyFhBQNml8Nu+miV"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9eedqz_r3as",
        "outputId": "ef5b8e69-5d17-4cdb-9eaa-ae821d71bc78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 98378, done.\u001b[K\n",
            "remote: Counting objects: 100% (884/884), done.\u001b[K\n",
            "remote: Compressing objects: 100% (476/476), done.\u001b[K\n",
            "remote: Total 98378 (delta 477), reused 730 (delta 385), pack-reused 97494 (from 1)\u001b[K\n",
            "Receiving objects: 100% (98378/98378), 621.96 MiB | 19.74 MiB/s, done.\n",
            "Resolving deltas: 100% (71461/71461), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/tensorflow/models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "from IPython import display\n",
        "base_name = checkpoint_name = 'mobilenet_v2_1.0_224' #@param\n",
        "url = 'https://storage.googleapis.com/mobilenet_v2/checkpoints/' + checkpoint_name + '.tgz'\n",
        "print('Downloading from ', url)\n",
        "!wget {url}\n",
        "print('Unpacking')\n",
        "!tar -xvf {checkpoint_name}.tgz\n",
        "checkpoint = checkpoint_name + '.ckpt'\n",
        "\n",
        "display.clear_output()\n",
        "print('Successfully downloaded checkpoint from ', url,\n",
        "      '. It is available as', checkpoint)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7udJpTcr86V",
        "outputId": "8ac41853-d712-46e1-b5c4-27e201883772"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded checkpoint from  https://storage.googleapis.com/mobilenet_v2/checkpoints/mobilenet_v2_1.0_224.tgz . It is available as mobilenet_v2_1.0_224.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://upload.wikimedia.org/wikipedia/commons/f/fe/Giant_Panda_in_Beijing_Zoo_1.JPG -O panda.jpg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0gcPtWSr_8p",
        "outputId": "d4857b35-5ee3-4f32-bb2c-5867986df736"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-07 03:34:50--  https://upload.wikimedia.org/wikipedia/commons/f/fe/Giant_Panda_in_Beijing_Zoo_1.JPG\n",
            "Resolving upload.wikimedia.org (upload.wikimedia.org)... 103.102.166.240, 2001:df2:e500:ed1a::2:b\n",
            "Connecting to upload.wikimedia.org (upload.wikimedia.org)|103.102.166.240|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 116068 (113K) [image/jpeg]\n",
            "Saving to: ‘panda.jpg’\n",
            "\n",
            "panda.jpg           100%[===================>] 113.35K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-11-07 03:34:50 (928 KB/s) - ‘panda.jpg’ saved [116068/116068]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/models/research/slim')\n",
        "\n",
        "# Install the tf_slim package\n",
        "!pip install tf_slim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cuNweUrsDLG",
        "outputId": "65b896dc-ff40-4dae-d4b9-694bce684f30"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tf_slim in /usr/local/lib/python3.10/dist-packages (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf_slim) (1.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checkpoint based inference"
      ],
      "metadata": {
        "id": "6BuVHkiasOli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Load the MobileNetV2 model from tf.keras (no top layers, for feature extraction)\n",
        "mobilenet_v2_model = tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Set the model to inference mode (no training)\n",
        "mobilenet_v2_model.trainable = False\n",
        "\n",
        "# Example of a random image (replace with actual image loading)\n",
        "images = np.random.random((1, 224, 224, 3))\n",
        "\n",
        "# Get feature maps from the model (equivalent to 'endpoints' in tf-slim)\n",
        "features = mobilenet_v2_model(images)\n",
        "\n",
        "print(features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBrUgYkzsIXm",
        "outputId": "29b1ac67-0b41-4a5f-d6dc-be2c2cfd8cfb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "(1, 7, 7, 1280)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYxq5Y-8sSO8",
        "outputId": "41a3e35b-82a8-4bbe-ebde-b6bd8a2d58bd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import decode_predictions\n",
        "\n",
        "# Load the MobileNetV2 model pre-trained on ImageNet\n",
        "mobilenet_v2_model = MobileNetV2(weights='imagenet', include_top=True)\n",
        "\n",
        "# Load and preprocess an image for prediction\n",
        "img_path = 'panda.jpg'  # replace with your image path\n",
        "img = Image.open(img_path)\n",
        "img = img.resize((224, 224))  # resize to 224x224 as expected by MobileNetV2\n",
        "img_array = np.array(img) / 255.0  # normalize the image\n",
        "\n",
        "\n",
        "# Check if eager execution is enabled\n",
        "print(\"Eager execution:\", tf.executing_eagerly())\n",
        "\n",
        "# Convert the image to a TensorFlow tensor (in case it's necessary)\n",
        "img_tensor = tf.convert_to_tensor(img_array, dtype=tf.float32)\n",
        "\n",
        "\n",
        "# Ensure eager execution is enabled before any other TensorFlow operations\n",
        "tf.compat.v1.enable_eager_execution()\n",
        "\n",
        "# Check if eager execution is enabled\n",
        "print(\"Eager execution:\", tf.executing_eagerly())\n",
        "\n",
        "# Make a prediction using the model\n",
        "predictions = mobilenet_v2_model.predict(img_array)\n",
        "\n",
        "# Decode predictions to human-readable labels\n",
        "decoded_predictions = decode_predictions(predictions, top=3)[0]\n",
        "\n",
        "# Print top 3 predictions\n",
        "for i, (imagenet_id, label, score) in enumerate(decoded_predictions):\n",
        "    print(f\"{i+1}: {label} ({score*100:.2f}%)\")\n"
      ],
      "metadata": {
        "id": "pZ6D43qQsXtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "img = np.array(PIL.Image.open('panda.jpg').resize((224, 224))).astype(np.float) / 128 - 1\n",
        "gd = tf.GraphDef.FromString(open(checkpoint_name + '_frozen.pb', 'rb').read())\n",
        "inp, predictions = tf.import_graph_def(gd,  return_elements = ['input:0', 'MobilenetV2/Predictions/Reshape_1:0'])"
      ],
      "metadata": {
        "id": "V1HL-cbcsbMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.Session(graph=inp.graph):\n",
        "  x = predictions.eval(feed_dict={inp: img.reshape(1, 224,224, 3)})\n",
        "\n",
        "label_map = imagenet.create_readable_names_for_imagenet_labels()\n",
        "print(\"Top 1 Prediction: \", x.argmax(),label_map[x.argmax()], x.max())"
      ],
      "metadata": {
        "id": "2L6cImkrsb8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-UmQaeVCseYw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}